==============================================
ðŸ“Œ Project Information
==============================================

ðŸ”¹ Main Project:
The goal of this project is to develop a robot capable of mapping an entire room. The generated map will then be uploaded to a database, allowing other users to download and utilize it for their own robots.

ðŸ”¹ Hardware in Use:
   â†’ Waveshare UGV02
   â†’ Raspberry Pi 5 + Active Cooler
   â†’ (Intel RealSense D415 camera)
   â†’ (2D/3D LiDAR sensor)

==============================================

ðŸ”¹ Side Project:
Additionally, the robot should be able to track and pursue a specific object within the mapped area.

ðŸ”¹ Hardware in Use:
   â†’ Waveshare UGV02
   â†’ Raspberry Pi 5 + Active Cooler
   â†’ Intel RealSense D415 camera

ðŸ”¹ Base Code: Intel RealSense (GitHub)
   â†’ https://github.com/IntelRealSense/librealsense/blob/jupyter/notebooks/distance_to_object.ipynb
   (Verified as of 01.02.2025)

ðŸ”¹ Object Detection Model: MobileNetSSD
   â†’ Downloaded from: https://github.com/chuanqi305/MobileNet-SSD
   - Model Files:
     - deploy.prototxt â†’ MobileNetSSD architecture
     - mobilenet_iter_73000.caffemodel â†’ Pre-trained weights

ðŸ”¹ PyRealSense2 for Raspberry Pi 5
   â†’ Currently, there is no "official" method from Intel, but this approach worked for me:
   - https://www.robotexchange.io/t/how-to-setup-the-intel-realsense-software-and-pyrealsense2-library-in-ubuntu-on-a-raspberryi-pi-5/3414

==============================================